{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "Packages"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\rimde\\anaconda3\\lib\\site-packages (0.1.59)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from yfinance) (2.24.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from yfinance) (0.0.9)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from yfinance) (4.6.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from yfinance) (1.19.2)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from yfinance) (1.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from pandas>=0.24->yfinance) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Requirement already satisfied: arch in c:\\users\\rimde\\anaconda3\\lib\\site-packages (4.19)\n",
      "Requirement already satisfied: cython>=0.29.14 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from arch) (0.29.21)\n",
      "Requirement already satisfied: property-cached>=1.6.4 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from arch) (1.6.4)\n",
      "Requirement already satisfied: statsmodels>=0.10 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from arch) (0.12.0)\n",
      "Requirement already satisfied: scipy>=1.2.3 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from arch) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from arch) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from arch) (1.19.2)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from statsmodels>=0.10->arch) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from pandas>=0.23->arch) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from pandas>=0.23->arch) (2020.1)\n",
      "Requirement already satisfied: six in c:\\users\\rimde\\anaconda3\\lib\\site-packages (from patsy>=0.5->statsmodels>=0.10->arch) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#Installing packages\n",
    "!pip install yfinance\n",
    "!pip install arch\n",
    "!pip install hurst\n",
    "\n",
    "import yfinance as yf  #Package to extract data from yahoofinance.com\n",
    "import pandas as pd    #Package to process data in dataframes\n",
    "import math            #Package to assess N/A\n",
    "import numpy as np     #Package to compute returns\n",
    "import datetime        #Package to enter the dates correctly \n",
    "import matplotlib.pyplot as plt  #Package to plot series\n",
    "import  statsmodels.api as sm   #Package to run an OLS regression on the log_prices to establish cointegration\n",
    "\n",
    "from dateutil.relativedelta import relativedelta #Package to compute the rolling windows\n",
    "from arch.unitroot import PhillipsPerron #Package to test the stationarity of the residuals\n",
    "from hurst import compute_Hc  #Package to compute hurst exponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "tags": [
     "Basic",
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "#Function to save data extracted from yahoo finance as a cvs file\n",
    "def SaveData(df,dataname):\n",
    "    df.to_csv('./'+dataname+'.csv')\n",
    "\n",
    "#####################################################################################################\n",
    "#Function to extract data \n",
    "#####################################################################################################\n",
    "#Function to extract the data from yahoo finance\n",
    "def getData(tick):\n",
    "    ticker = yf.Ticker(tick)\n",
    "    dataname=tick\n",
    "    \n",
    "    #Extracting the closing price \n",
    "    data = ticker.history(start = start_date,end=end_date)\n",
    "    data = data[\"Close\"]\n",
    "    \n",
    "    #Extracting the dividends and splits\n",
    "    div_split=ticker.actions\n",
    "    \n",
    "    #Data processing the closing price to take into account stock splits\n",
    "    counter_1 = 0\n",
    "    for price in data[:len(data)]:\n",
    "        str_1 = data.index[counter_1]\n",
    "        counter_2 = 0\n",
    "        for day in div_split[\"Dividends\"][:len(div_split[\"Dividends\"])]:\n",
    "            str_2 = div_split[\"Dividends\"].index[counter_2]\n",
    "            if str_1 == str_2:\n",
    "                ratio = div_split[\"Stock Splits\"][counter_2]\n",
    "                if ratio!=0:\n",
    "                    counter_3=counter_1+1\n",
    "                    for gross_price in data[counter_1+1:len(data)]:\n",
    "                        gross_price = gross_price*ratio\n",
    "                        data.iat[counter_3] = gross_price\n",
    "                        counter_3+=1\n",
    "            counter_2+=1\n",
    "        counter_1 += 1\n",
    "    \n",
    "    #Data processing the closing price to add back dividends\n",
    "    counter_1 = 0\n",
    "    for price in data[:len(data)]:\n",
    "        str_1 = data.index[counter_1]\n",
    "        counter_2 = 0\n",
    "        for day in div_split[\"Dividends\"][:len(div_split[\"Dividends\"])]:\n",
    "            str_2 = div_split[\"Dividends\"].index[counter_2]\n",
    "            if str_1 == str_2:\n",
    "                dividend = div_split[\"Dividends\"][counter_2]\n",
    "                price = price + dividend\n",
    "                data.iat[counter_1] = price\n",
    "            counter_2+=1\n",
    "        counter_1 += 1\n",
    "    \n",
    "    data = pd.DataFrame(data)    \n",
    "    data.rename(columns={'Close':dataname},inplace =  True)\n",
    "    return data\n",
    "\n",
    "\n",
    "#Function to get the first row of available data\n",
    "def First(data):\n",
    "    counter=0\n",
    "    for ele in data:\n",
    "        if math.isnan(ele)==False:\n",
    "            break\n",
    "        counter+=1\n",
    "    return counter\n",
    "\n",
    "#Function to fill in the blanks\n",
    "def Filling(data):\n",
    "    start = First(data)\n",
    "    for ele in data[start:len(data)]:\n",
    "        if math.isnan(ele)==True:\n",
    "            data.iat[start] = data[start-1]\n",
    "        start+=1       \n",
    "    return data\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "#Function to compute based on a rolling window\n",
    "##############################################################################################################\n",
    " \n",
    "#Function to determine the 6 months date\n",
    "def resize_months(start_date, data, number_months):\n",
    "    start_date = data.index[start_date]\n",
    "    end_date = start_date+relativedelta(months=+number_months)\n",
    "    int_ = data.index.searchsorted(end_date)+1\n",
    "    return int_\n",
    "\n",
    "def clean_up(decision_window):\n",
    "    for ticker in decision_window:\n",
    "        lenght = (len(decision_window[ticker].dropna(axis=0)))\n",
    "        if lenght<25:\n",
    "            decision_window.drop(columns=[ticker],inplace = True)\n",
    "    return decision_window\n",
    "\n",
    "###############################################################################################################\n",
    "#Function used in pair construction\n",
    "###############################################################################################################\n",
    "\n",
    "#Function that take as a parameter a row of the pair dataframe and constructs a dataframe with their returns\n",
    "def pair_return(data,row):\n",
    "    df= pd.concat([data[row[0]],data[row[1]]],axis=1).dropna(axis=0)\n",
    "    return df\n",
    "\n",
    "#Function that retruns the index number of a date\n",
    "def index_number(date,data):\n",
    "    df_1 = data.copy()\n",
    "    df = pd.DataFrame(df_1)\n",
    "    df['A']=np.arange(len(df))\n",
    "    return df['A'][date]\n",
    "\n",
    "#Function to clean up data in order to avoid having two values for the same date\n",
    "def clean_up_data(data):\n",
    "    return data.reset_index().drop_duplicates(subset='index').set_index('index')\n",
    "\n",
    "#Function to avoid double pairs and returns a boolean\n",
    "def check_double(data, row):\n",
    "    test=False\n",
    "    for ele in data:\n",
    "        if set(ele)==set(row):\n",
    "            test= True\n",
    "    return test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": true,
    "tags": [
     "correlation"
    ]
   },
   "outputs": [],
   "source": [
    "######################################################CORRELATION BASED PORTFOLIO##############################################\n",
    "\n",
    "#############################################################################################################\n",
    "#Functions related to the best pair based on correlation\n",
    "#############################################################################################################\n",
    "\n",
    "#Function to determine the max other than 1 \n",
    "def max_corr(data):\n",
    "    max_ = -1\n",
    "    for ele in data : \n",
    "        if max_< ele and ele!=1: \n",
    "            max_=ele\n",
    "    return max_\n",
    "            \n",
    "#Function that returns the perfect pair for a given list \n",
    "def pair_of(data):\n",
    "    counter = 0 \n",
    "    for corr in data:\n",
    "        if corr == max_corr(data):\n",
    "            break\n",
    "        counter+=1\n",
    "    return data.index[counter]\n",
    "\n",
    "##############################################################################################################\n",
    "#Function that returns a dataframe containing all the pairs based on correlation\n",
    "##############################################################################################################\n",
    "def pairs(returns):\n",
    "    corr_matrix = returns.corr(method='spearman')\n",
    "    matrix=[]\n",
    "    pair_1 = corr_matrix.index[0]\n",
    "    pair_2 = pair_of(corr_matrix[pair_1])\n",
    "    row = [pair_1,pair_2]\n",
    "    matrix.append(row)\n",
    "    for ele in corr_matrix.index:\n",
    "        pair_1 = ele\n",
    "        pair_2 = pair_of(corr_matrix[pair_1])\n",
    "        row = [pair_1,pair_2]\n",
    "        if check_double(matrix,row)==False:\n",
    "            matrix = np.vstack([matrix,row])\n",
    "    return matrix      \n",
    "\n",
    "############################################################################################################\n",
    "#Function to compute rolling correlation for a six month period takes as parameter pair return\n",
    "############################################################################################################\n",
    "def rolling_corr(data):\n",
    "    #Initializing\n",
    "    corr_6m =[]\n",
    "    index=[]\n",
    "\n",
    "    #Adjusting the run_time of the loop\n",
    "    if len(data)>27:\n",
    "        adjust_ = 1\n",
    "    elif len(data) <= 27: \n",
    "        adjust_ = len(data) - 27\n",
    "     \n",
    "    for start_date in range(len(data)-25-adjust_):\n",
    "        \n",
    "        #Specifying the rolling window\n",
    "        end_date = resize_months(start_date,data,6)\n",
    "        if len(data)<end_date: \n",
    "            end_date = len(data)\n",
    "        index.append(data.index[end_date-1])\n",
    "        window = data[start_date:end_date]\n",
    "        \n",
    "        #Computing the correlation\n",
    "        corr = window.corr(method='spearman')[data.columns[0]][data.columns[1]]\n",
    "        \n",
    "        #Stocking the correlation in the matrix\n",
    "        corr_6m.append(corr)\n",
    "        \n",
    "    #Reindexing\n",
    "    corr_6m = pd.DataFrame(corr_6m)\n",
    "    for i in range(0,len(corr_6m)):\n",
    "        corr_6m.rename(index={i:index[i]},inplace = True)\n",
    "    corr_6m.rename(columns={0:'Rolling Correlation'},inplace = True)\n",
    "    \n",
    "    return clean_up_data(corr_6m)\n",
    " \n",
    "###############################################################################################################\n",
    "#Function to compute the moving average of the series takes as a parameter the rolling correlation\n",
    "###############################################################################################################\n",
    "def moving_average(rolling_cor):\n",
    "    #Initializing\n",
    "    moving_aver = []\n",
    "    index=[]\n",
    "    \n",
    "    #Adjusting the run_time of the loop\n",
    "    if len(rolling_cor)>27:\n",
    "        adjust = 1\n",
    "    elif len(rolling_cor) < 27 or len(rolling_cor)==27: \n",
    "        adjust = len(rolling_cor) - 27\n",
    "\n",
    "    for start_date in range(0,len(rolling_cor)-24-adjust):\n",
    "        #Specifying the moving window\n",
    "        end_date = resize_months(start_date,rolling_cor,6)\n",
    "        if len(rolling_cor)<end_date: \n",
    "            end_date = len(rolling_cor)\n",
    "        \n",
    "        index.append(rolling_cor.index[end_date-1])\n",
    "        window = rolling_cor[start_date:end_date]\n",
    "        \n",
    "        #Computing the mean and the vol\n",
    "        mean = window.mean()[0]\n",
    "        vol = np.std(window)[0]\n",
    "        moving_aver.append([mean,vol])\n",
    "        \n",
    "    #Reindexing\n",
    "    moving_aver = pd.DataFrame(moving_aver)\n",
    "    for i in range(0,len(moving_aver)):\n",
    "        moving_aver.rename(index={i:index[i]},inplace = True)\n",
    "    moving_aver.rename(columns={0: 'Correlation Mean', 1: 'Correlation Vol'},inplace = True)\n",
    "    return clean_up_data(moving_aver)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "#Function that executes the trading strategy of the pair\n",
    "##############################################################################################################\n",
    "def trading_correlation(computation_window,trading_window, row_of_pair, delta_entry, delta_exit):\n",
    "    \n",
    "    #Stocking data in respective variable\n",
    "    returns = pair_return(computation_window,row_of_pair)\n",
    "    prices = pair_return(adj_close_w,row_of_pair)\n",
    "    df = pd.concat([rolling_corr(returns),moving_average(rolling_corr(returns))],axis=1).dropna(axis=0)\n",
    "    \n",
    "    rolling_correlation = df['Rolling Correlation']\n",
    "    moving_avrg = df['Correlation Mean']\n",
    "    stdev = df['Correlation Vol']\n",
    "\n",
    "    \n",
    "    #Initializing\n",
    "    weights_1 = 0\n",
    "    weights_2 = 0\n",
    "    signal_1 = False \n",
    "    signal_2 = False\n",
    "    portfolio = []\n",
    "    \n",
    "    #Executing the trade for the given period\n",
    "    for i in range(len(trading_window)):\n",
    "        \n",
    "        #Stocking info in  respective variable\n",
    "        date = trading_window.index[i]\n",
    "        return_1 = returns[row_of_pair[0]][date]\n",
    "        return_2 = returns[row_of_pair[1]][date]\n",
    "        price_1 = prices[row_of_pair[0]][date]\n",
    "        price_2 = prices[row_of_pair[1]][date]\n",
    "        \n",
    "        #Finding the earliest date with rolling correlation its mean and it vol available\n",
    "        date_r = rolling_correlation.index.searchsorted(date)\n",
    "        if date_r >= len(rolling_correlation): \n",
    "            date_r += -1 # len(rolling_correlation.index)\n",
    "        date_r = rolling_correlation.index[date_r]\n",
    "        correlation = rolling_correlation[date_r]\n",
    "        mean = moving_avrg[date_r]\n",
    "        vol = stdev[date_r]\n",
    "\n",
    "        #Readjusting weights of the price\n",
    "        if correlation < mean - delta_entry*vol:   #Trading strategy is triggered \n",
    "            #Determining the overpriced and undervalued stock \n",
    "            if return_1 > return_2: \n",
    "                weights_1 += -1\n",
    "                weights_2 += 1\n",
    "            else:\n",
    "                weights_1 += 1\n",
    "                weights_2 += -1\n",
    "            signal_1 = True\n",
    "            \n",
    "        elif correlation > mean + delta_exit and signal_1 == True:   #Unwind the trading strategy\n",
    "            weights_1 = 0 \n",
    "            weights_2 = 0\n",
    "            \n",
    "                \n",
    "        elif correlation > mean + delta_entry:   #Trading strategy is triggered\n",
    "            #Determining the overpriced and undervalued stock\n",
    "            if return_1 < return_2: \n",
    "                weights_1 += -1\n",
    "                weights_2 += 1\n",
    "            else:\n",
    "                weights_1 += 1\n",
    "                weights_2 += -1\n",
    "            signal_2 = True \n",
    "        \n",
    "        elif correlation < mean - delta_exit and signal_1 == True:   #Unwind the trading strategy\n",
    "            weights_1 = 0 \n",
    "            weights_2 = 0\n",
    "        \n",
    "        #print(weights_1, ' ___ ', weights_2)\n",
    "        portfolio.append(weights_1*price_1 + weights_2*price_2)\n",
    "    \n",
    "    #Reindexing\n",
    "    portfolio = pd.DataFrame(portfolio)\n",
    "    for i in range(0,len(portfolio)):\n",
    "        portfolio.rename(index={i:trading_window.index[i]},inplace = True)\n",
    "    portfolio.rename(columns={0:'Portfolio Value '+ row_of_pair[0]+'-'+row_of_pair[1]},inplace = True)\n",
    "    \n",
    "    return portfolio\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "scrolled": true,
    "tags": [
     "correlation"
    ]
   },
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "###Executing the strategy on a rolling basis: first year to construct the pairs then execute the trading strategy in the \n",
    "#following six months, the pair selection is refreshed using the accumulated data since the first initial year \n",
    "##############################################################################################################################\n",
    "\n",
    "def execution_correlation_strategy(weekly_ret,delta_entry,delta_exit):\n",
    "    #Initializing\n",
    "    #Defining the dataframe that will contain\n",
    "    correlation_portfolio=[]\n",
    "\n",
    "    #Decision window based on which the pairs will be traded\n",
    "    decision_end_date = resize_months(0,weekly_ret,12)\n",
    "    decision_window = clean_up(weekly_ret[1:decision_end_date])\n",
    "\n",
    "    #Trading window based on which the trading strategy will be executed\n",
    "    trading_start_date = decision_end_date + 1\n",
    "    trading_end_date = resize_months(trading_start_date,weekly_ret,6)\n",
    "    trading_window = weekly_ret[trading_start_date:trading_end_date].dropna(axis=1,thresh =2)\n",
    "\n",
    "    #Computation window based on which we will be computing the rolling correlation, its mean and its vol\n",
    "    computation_window = weekly_ret[0:trading_end_date]\n",
    "\n",
    "    #Determining the pair trade based on a initial one year window and expanding\n",
    "    matrix = pairs(decision_window)\n",
    "\n",
    "    #Executing the pair trade based on the distance method for all pairs in the matrix\n",
    "    portfolio_ret = pd.DataFrame(trading_correlation(pair_return(computation_window,matrix[0]),pair_return(\n",
    "        trading_window,matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "    for row in matrix[1:]:\n",
    "        portfolio_ret = pd.concat([portfolio_ret,trading_correlation(pair_return(computation_window,row),pair_return(\n",
    "        trading_window,row), row,delta_entry,delta_exit)],axis=1)\n",
    "    portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1)) \n",
    "    correlation_portfolio = portfolio_ret\n",
    "\n",
    "    #Looping for the rest of the period\n",
    "    for start_date in range(1,len(weekly_ret)-81):\n",
    "\n",
    "        #Decision window based on which the pairs will be traded\n",
    "        decision_end_date = resize_months(start_date,weekly_ret,12)\n",
    "        decision_window = clean_up(weekly_ret[0:decision_end_date])\n",
    "\n",
    "        #Trading window based on which correlation will be evaluated and the trade strategy will be executed\n",
    "        trading_start_date = decision_end_date + 1\n",
    "        trading_end_date = resize_months(trading_start_date,weekly_ret,6)\n",
    "        if trading_end_date>len(weekly_ret):\n",
    "            trading_end_date = len(weekly_ret)\n",
    "        trading_window = weekly_ret[trading_start_date:trading_end_date].dropna(axis=1,thresh = 2)\n",
    "\n",
    "        #Computation window based on which we will be computing the rolling correlation, its mean and its vol\n",
    "        computation_window = weekly_ret[0:trading_end_date]\n",
    "\n",
    "        #Determining the pair trade based on a initial one year window and expanding\n",
    "        matrix = pairs(decision_window)\n",
    "\n",
    "        #Executing the pair trade based on correlation\n",
    "        portfolio_ret = pd.DataFrame(trading_correlation(pair_return(computation_window,matrix[0]),pair_return(\n",
    "            trading_window,matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "\n",
    "        for row in matrix[1:]:\n",
    "            portfolio_ret = pd.concat([portfolio_ret,trading_correlation(pair_return(computation_window,row),pair_return(\n",
    "                trading_window,row), row,delta_entry,delta_exit)],axis=1)\n",
    "        portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1))\n",
    "        correlation_portfolio = pd.concat([correlation_portfolio,portfolio_ret],axis=0)\n",
    "\n",
    "    #Computing the returns of the portfolio based on correlation\n",
    "    correlation_portfolio.rename(columns={0:'Correlation Portfolio'},inplace = True)\n",
    "    correlation_portfolio_ret = ((correlation_portfolio - correlation_portfolio.shift(1))/correlation_portfolio.shift(1)).fillna(0)\n",
    "    correlation_portfolio_ret.rename(columns={'Correlation Portfolio':'Correlation Portfolio Returns'},inplace = True)\n",
    "    return correlation_portfolio_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "tags": [
     "Cointegration"
    ]
   },
   "outputs": [],
   "source": [
    "##################################################COINTEGRATION BASED PORTFOLIO################################################\n",
    "\n",
    "####################################################################################################################\n",
    "#Function that takes as parameters adj closing prices and returns a matrix with the most suited pairs\n",
    "####################################################################################################################\n",
    "\n",
    "def cointegration (data):\n",
    "    data = np.log(data)\n",
    "    matrix = [\"_\",\"_\"]\n",
    "    for ticker_1 in data.columns:\n",
    "        #Dataframe to stock all p_values\n",
    "        p_value=[]\n",
    "        \n",
    "        #Looping through tickers \n",
    "        for ticker_2 in data.columns:\n",
    "            \n",
    "            #Computing the p_value for each other stock\n",
    "            if ticker_1 != ticker_2:\n",
    "                data_coint = pair_return(data,[ticker_1,ticker_2]).dropna(axis=0)\n",
    "                Y =  data_coint[ticker_1]\n",
    "                X = data_coint[ticker_2]\n",
    "                X = sm.add_constant(X)\n",
    "                ols_regression = sm.OLS(Y,X).fit()\n",
    "                residuals = Y - ols_regression.fittedvalues\n",
    "                if math.isnan(residuals.sum(axis=0))==False and len(residuals.dropna(axis=0))>4:\n",
    "                    pp = PhillipsPerron(residuals.dropna(axis=0))\n",
    "                    p_value.append([ticker_2,pp.pvalue])\n",
    "        \n",
    "        #Deteminin the most cointegrated ticker_2 with ticker_1\n",
    "        p_value = pd.DataFrame(p_value)\n",
    "        for i in range(len(p_value[1])): \n",
    "            if p_value[1][i] == p_value[1].max():\n",
    "                row = [ticker_1,p_value[0][i]]\n",
    "                \n",
    "        #Stocking the pairs in a matrix\n",
    "        if check_double(matrix,row)==False:\n",
    "            matrix = np.vstack([matrix,row])\n",
    "            \n",
    "    return matrix[1:]\n",
    "\n",
    "###################################################################################################################\n",
    "#Function to extract the moving mean of the cointegrated model and the cointegrated coefficient\n",
    "###################################################################################################################\n",
    "def moving_mean_coef(data):  #adj_close_w only contains the two tickers\n",
    "    moving_mean = []\n",
    "    index=[]\n",
    "    \n",
    "    #Adjusting the run_time of the loop\n",
    "\n",
    "    if len(data) == 27 :\n",
    "        adjust = 0 \n",
    "    elif len(data)>27:\n",
    "        adjust = 1\n",
    "    elif len(data) < 27: \n",
    "        adjust = len(data) - 27\n",
    "        \n",
    "    for start_date in range(len(data)-26-adjust):\n",
    "        \n",
    "        #Defining the rolling window\n",
    "        end_date = resize_months(start_date,data,6)\n",
    "        if len(data)<end_date: \n",
    "            end_date = len(data)\n",
    "        index.append(data.index[end_date-1])\n",
    "        window = data[start_date:end_date]\n",
    "        \n",
    "        #Running the regression on the rolling window\n",
    "        Y = window[data.columns[0]]\n",
    "        X = window[data.columns[1]]\n",
    "        X = sm.add_constant(X)\n",
    "        ols_regression = sm.OLS(Y,X).fit()\n",
    "        stdev= np.std(Y-ols_regression.params[1]*window[data.columns[1]])\n",
    "        moving_mean.append([ols_regression.params[0],ols_regression.params[1],stdev])\n",
    "        \n",
    "        \n",
    "    #Reindexing\n",
    "    moving_mean = pd.DataFrame(moving_mean)\n",
    "    for i in range(0,len(moving_mean)):\n",
    "        moving_mean.rename(index={i:index[i]},inplace = True)\n",
    "    moving_mean.rename(columns={0:'Cointegration Mean',1:'Cointegration Coefficient',2:'Volatility of the Spread'},inplace = True)\n",
    "    \n",
    "    return clean_up_data(moving_mean)\n",
    "\n",
    "##########################################################################################################################\n",
    "#Function to execute the trading strategy based on cointegration and returns a DataFrame of the value of the portfolio\n",
    "##########################################################################################################################\n",
    "def trading_cointegration(adj_close_w, row_of_pair, delta_entry,  delta_exit):\n",
    "    \n",
    "    #Stocking data in respective variable\n",
    "    prices = pair_return(adj_close_w,row_of_pair)\n",
    "    coint_mean_coef = moving_mean_coef(prices)\n",
    "\n",
    "    spread = prices[row_of_pair[0]]-coint_mean_coef['Cointegration Coefficient']*prices[row_of_pair[1]]\n",
    "    \n",
    "     #Initializing\n",
    "    weights_1 = 0\n",
    "    weights_2 = 0\n",
    "    portfolio = []\n",
    "    signal_1 = False \n",
    "    signal_2 = False\n",
    "    \n",
    "    \n",
    "    #Executing the trade for the given period\n",
    "    for i in range(len(coint_mean_coef)):\n",
    "\n",
    "        #Stocking info in  respective variable\n",
    "        date = coint_mean_coef.index[i]\n",
    "        price_1 = prices[row_of_pair[0]][date]\n",
    "        price_2 = prices[row_of_pair[1]][date]\n",
    "        \n",
    "        stdv = coint_mean_coef['Volatility of the Spread'][date]\n",
    "        coint_mean = coint_mean_coef['Cointegration Mean'][date]\n",
    "        spread_t = spread [date]\n",
    "\n",
    "        \n",
    "        #Readjusting weights \n",
    "        if spread_t < coint_mean - delta_entry*stdv :\n",
    "            weights_1 +=1\n",
    "            weights_2 +=-1\n",
    "            signal_1 = True\n",
    "        elif signal_1 == True and spread_t > coint_mean + delta_exit*stdv: \n",
    "            weights_1 =0\n",
    "            weights_2 =0\n",
    "            signal_1 = False\n",
    "        \n",
    "        elif spread_t > coint_mean + delta_entry*stdv:\n",
    "            weights_1+=-1\n",
    "            weights_2+=1\n",
    "            signal_2 = True\n",
    "        elif signal_2 == True and spread_t < coint_mean - delta_exit*stdv:\n",
    "            weights_1 =0\n",
    "            weights_2 =0\n",
    "            signal_2 = False\n",
    "        \n",
    "        portfolio.append(weights_1*price_1 + weights_2*price_2) \n",
    "       \n",
    "    #Reindexing\n",
    "    portfolio = pd.DataFrame(portfolio)\n",
    "    for i in range(0,len(portfolio)):\n",
    "        portfolio.rename(index={i:coint_mean_coef.index[i]},inplace = True)\n",
    "    portfolio.rename(columns={0:'Portfolio Returns '+row[0]+'-'+row[1]},inplace = True)\n",
    " \n",
    "    return portfolio\n",
    "\n",
    "\n",
    "##############################################################################################################################\n",
    "###Executing the strategy on a rolling basis: first year to construct the pairs then execute the trading strategy in the \n",
    "#following six months, the pair selection is refreshed using the accumulated data since the first initial year \n",
    "##############################################################################################################################\n",
    "def execution_cointegration_method(adj_close_w, delta_entry,delta_exit):\n",
    "    #Initializing\n",
    "    #Defining the dataframe that will contain the portfolio\n",
    "    cointegration_portfolio=[]\n",
    "\n",
    "    #Decision window based on which the pairs will be traded\n",
    "    decision_end_date = resize_months(0,adj_close_w,12)\n",
    "    decision_window = clean_up(adj_close_w[1:decision_end_date])\n",
    "\n",
    "    #Trading window based on which cointegration will be evaluated and the trade strategy will be executed\n",
    "    trading_start_date = decision_end_date + 1\n",
    "    trading_end_date = resize_months(trading_start_date,adj_close_w,6)\n",
    "    trading_window = adj_close_w[trading_start_date:trading_end_date].dropna(axis=1,thresh=10)\n",
    "\n",
    "\n",
    "    #Determining the pair trade based on a initial one year window and expanding\n",
    "    matrix = cointegration(decision_window)\n",
    "\n",
    "    #Executing the pair trade based on cointegration for all pairs in the matrix\n",
    "    portfolio_ret = pd.DataFrame(trading_cointegration(pair_return(trading_window, matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "    for row in matrix[1:]:\n",
    "        portfolio_ret = pd.concat([portfolio_ret,trading_cointegration(pair_return(trading_window,row), row,delta_entry,delta_exit)],axis=1)\n",
    "    portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1)) \n",
    "    cointegration_portfolio = portfolio_ret\n",
    "\n",
    "\n",
    "    #Looping for the rest of the period\n",
    "    for start_date in range(1,len(adj_close_w)-81):\n",
    "\n",
    "        #Decision window based on which the pairs will be traded\n",
    "        decision_end_date = resize_months(start_date,adj_close_w,12)\n",
    "        decision_window = clean_up(adj_close_w[1:decision_end_date])\n",
    "\n",
    "        #Trading window based on which cointegration will be evaluated and the trade strategy will be executed\n",
    "        trading_start_date = decision_end_date + 1\n",
    "        trading_end_date = resize_months(trading_start_date,adj_close_w,6)\n",
    "        if trading_end_date>len(adj_close_w):\n",
    "            trading_end_date = len(adj_close_w)\n",
    "        trading_window = adj_close_w[trading_start_date:trading_end_date].dropna(axis=1,thresh=10)\n",
    "\n",
    "        #Determining the pair trade based on a initial one year window and expanding\n",
    "        matrix = cointegration(decision_window)\n",
    "\n",
    "        #Executing the pair trade based on cointegration\n",
    "        portfolio_ret = pd.DataFrame(trading_cointegration(pair_return(trading_window, matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "        for row in matrix[1:]:\n",
    "            portfolio_ret = pd.concat([portfolio_ret,trading_cointegration(pair_return(trading_window,row), row,delta_entry,delta_exit)],axis=1)\n",
    "        portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1))\n",
    "        cointegration_portfolio = pd.concat([cointegration_portfolio,portfolio_ret],axis=0)\n",
    "\n",
    "    #Computing the returns of the portfolio\n",
    "    cointegration_portfolio.rename(columns={0:'Cointegration Portfolio'},inplace = True)\n",
    "    cointegration_portfolio_ret = ((cointegration_portfolio - cointegration_portfolio.shift(1))/cointegration_portfolio.shift(1)).fillna(0).fillna(0)\n",
    "    cointegration_portfolio_ret.rename(columns={0:'Cointegration Portfolio Returns'},inplace = True)\n",
    "    return cointegration_portfolio_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################DISTANCE METHOD BASED PORTFOLIO###########################################\n",
    "\n",
    "##########################################################################################################################\n",
    "#Function that takes as parameters returns a matrix with the most suited pairs\n",
    "##########################################################################################################################\n",
    "#Meaning the pair that have the lowest sum of squared differences between the cumulative return\n",
    "def distance_method_pairs(data):#the data is returns\n",
    "    \n",
    "    #Initializing\n",
    "    matrix = [\"_\",\"_\"]\n",
    "    \n",
    "    #Because we are dealing with cumulative differences\n",
    "    data = data.dropna(axis=0)\n",
    "    \n",
    "    #Selecting the best pairs\n",
    "    for ticker_1 in data.columns:\n",
    "        \n",
    "        #Dataframe to stock all SSD\n",
    "        SSD =[]\n",
    "        \n",
    "        #Looping through all pairs to compute the squared difference\n",
    "        for ticker_2 in data.columns:\n",
    "            if ticker_1!=ticker_2:\n",
    "                cum_returns = pair_return(data,[ticker_1,ticker_2]).cumsum()\n",
    "                Squared_Diff = (cum_returns[ticker_1]-cum_returns[ticker_2])**2\n",
    "                SSD.append([ticker_2,Squared_Diff.sum(axis =0)])\n",
    "        \n",
    "        #Detemining the shortest distance between ticker_1 and ticker 2\n",
    "        SSD = pd.DataFrame(SSD)\n",
    "        for i in range(len(SSD[1])): \n",
    "            if SSD[1][i] == SSD[1].min():\n",
    "                row = [ticker_1,SSD[0][i]]\n",
    "                \n",
    "        #Stocking the pairs in a matrix\n",
    "        if check_double(matrix,row)==False:\n",
    "            matrix = np.vstack([matrix,row])\n",
    "            \n",
    "    return matrix[1:]\n",
    "\n",
    "##############################################################################################################################\n",
    "#Function to execute the trading strategy based on the distance method and returns a DataFrame of the value of the portfolio\n",
    "##############################################################################################################################\n",
    "def trading_distance_method(returns, row_of_pair, delta_entry, delta_exit):\n",
    "    \n",
    "    #Stocking data in respective variable\n",
    "    prices = pair_return(adj_close_w,row_of_pair)\n",
    "    returns = pair_return(returns,row_of_pair)\n",
    "    \n",
    "     #Initializing\n",
    "    weights_1 = 0\n",
    "    weights_2 = 0\n",
    "    signal_1 = False \n",
    "    signal_2 = False\n",
    "    portfolio = []\n",
    "    \n",
    "    #Executing the trade for the given period\n",
    "    for i in range(len(returns)):\n",
    "        \n",
    "        #Stocking info in  respective variable\n",
    "        date = returns.index[i]\n",
    "        price_1 = prices[row_of_pair[0]][date]\n",
    "        price_2 = prices[row_of_pair[1]][date]\n",
    "        return_1 = returns[row_of_pair[0]][date]\n",
    "        return_2 = returns[row_of_pair[1]][date]\n",
    "      \n",
    "        vol_1 = np.std(returns[row_of_pair[0]][:date])\n",
    "        vol_2 = np.std(returns[row_of_pair[1]][:date])\n",
    "        spread = return_1/vol_1 - return_2/vol_2\n",
    "    \n",
    "       \n",
    "        #Readjusting weights \n",
    "        if spread < delta_entry :\n",
    "            weights_1 +=1\n",
    "            weights_2 +=-1\n",
    "            signal_1 = True\n",
    "        elif signal_1 == True and spread > delta_exit: \n",
    "            weights_1 =0\n",
    "            weights_2 =0\n",
    "            signal_1 = False\n",
    "        \n",
    "        elif spread > delta_entry:\n",
    "            weights_1+=-1\n",
    "            weights_2+=1\n",
    "            signal_2 = True\n",
    "        elif signal_2 == True and spread < delta_exit:\n",
    "            weights_1 =0\n",
    "            weights_2 =0\n",
    "            signal_2 = False\n",
    "                  \n",
    "        portfolio.append(weights_1*price_1 + weights_2*price_2)\n",
    "        \n",
    "    #Reindexing\n",
    "    portfolio = pd.DataFrame(portfolio)\n",
    "    for i in range(len(portfolio)):\n",
    "        portfolio.rename(index={i:returns.index[i]},inplace = True)\n",
    "    portfolio.rename(columns={0:'Portfolio '+row[0]+'-'+row[1]},inplace = True)\n",
    "\n",
    "    return portfolio\n",
    "\n",
    "##############################################################################################################################\n",
    "###Executing the strategy on a rolling basis: first year to construct the pairs then execute the trading strategy in the \n",
    "#following six months, the pair selection is refreshed using the accumulated data since the first initial year \n",
    "##############################################################################################################################\n",
    "def execution_distance_model_strategy(weekly_ret, delta_entry, delta_exit):\n",
    "\n",
    "    #Initializing\n",
    "    #Defining the dataframe that will contain\n",
    "    distance_method_portfolio=[]\n",
    "\n",
    "    #Decision window based on which the pairs will be traded\n",
    "    decision_end_date = resize_months(0,weekly_ret,12)\n",
    "    decision_window = clean_up(weekly_ret[0:decision_end_date])\n",
    "\n",
    "    #Trading window based on which the trading strategy will be executed\n",
    "    trading_start_date = decision_end_date + 1\n",
    "    trading_end_date = resize_months(trading_start_date,weekly_ret,6)\n",
    "    trading_window = weekly_ret[trading_start_date:trading_end_date].dropna(axis=1,thresh=10)\n",
    "\n",
    "\n",
    "    #Determining the pair trade based on a initial one year window and expanding\n",
    "    matrix = distance_method_pairs(decision_window)\n",
    "\n",
    "    #Executing the pair trade based on the distance method for all pairs in the matrix\n",
    "    portfolio_ret = pd.DataFrame(trading_distance_method(pair_return(trading_window, matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "    for row in matrix[1:]:\n",
    "        portfolio_ret = pd.concat([portfolio_ret,trading_distance_method(pair_return(trading_window,row),row,delta_entry,delta_exit)],axis=1)\n",
    "    portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1)) \n",
    "    distance_method_portfolio = portfolio_ret\n",
    "\n",
    "    #Looping for the rest of the period\n",
    "    for start_date in range(1,len(weekly_ret)-81):\n",
    "\n",
    "        #Decision window based on which the pairs will be traded\n",
    "        decision_end_date = resize_months(start_date,weekly_ret,12)\n",
    "        decision_window = clean_up(weekly_ret[0:decision_end_date])\n",
    "\n",
    "        #Trading window based on which the distance method will be evaluated and the trade strategy will be executed\n",
    "        trading_start_date = decision_end_date + 1\n",
    "        trading_end_date = resize_months(trading_start_date,weekly_ret,6)\n",
    "        if trading_end_date>len(weekly_ret):\n",
    "            trading_end_date = len(weekly_ret)\n",
    "        trading_window = weekly_ret[trading_start_date:trading_end_date].dropna(axis=1,thresh=10)\n",
    "\n",
    "        #Determining the pair trade based on a initial one year window and expanding\n",
    "        matrix = distance_method_pairs(decision_window)\n",
    "\n",
    "\n",
    "        #Executing the pair trade based on the distance method\n",
    "        portfolio_ret = pd.DataFrame(trading_distance_method(pair_return(trading_window, matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "        for row in matrix[1:]:\n",
    "            portfolio_ret = pd.concat([portfolio_ret,trading_distance_method(pair_return(trading_window,row), row,delta_entry,delta_exit)],axis=1)\n",
    "        portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1))\n",
    "        distance_method_portfolio = pd.concat([distance_method_portfolio,portfolio_ret],axis=0)\n",
    "    distance_method_portfolio.rename(columns={0:'Distance Portfolio'},inplace = True)\n",
    "\n",
    "    #Computing the returns of the portfolio based on the distance method\n",
    "    distance_method_portfolio_ret = ((distance_method_portfolio - distance_method_portfolio.shift(1))/distance_method_portfolio.shift(1)).fillna(0)\n",
    "    distance_method_portfolio_ret.rename(columns={'Distance Portfolio':'Distance Portfolio Returns'},inplace = True)\n",
    "    \n",
    "    return distance_method_portfolio_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## HURTS EXPONENT METHOD BASED PORTFOLIO ##########################################\n",
    "\n",
    "##########################################################################################################################\n",
    "#Function that takes as parameters returns a matrix with the most suited pairs\n",
    "##########################################################################################################################\n",
    "#Meaning the pair that have the lowest sum of squared differences between the cumulative return\n",
    "def hurst_exponent_pairs(price,returns):#the data is ajd_close\n",
    "    \n",
    "    #Initializing\n",
    "    matrix = [\"_\",\"_\"]\n",
    "    \n",
    "    #\n",
    "    \n",
    "    #Selecting the best pairs\n",
    "    for ticker_1 in price.columns:\n",
    "        \n",
    "        if len(price[ticker_1].dropna(axis=0))>100:\n",
    "            \n",
    "            #Dataframe to stock all hurst exponent\n",
    "            Hurst =[]\n",
    "\n",
    "            #Looping through all pairs to compute the time series\n",
    "            for ticker_2 in price.columns:\n",
    "\n",
    "                price_ = pair_return(price,[ticker_1,ticker_2])\n",
    "                returns_ = pair_return(price,[ticker_1,ticker_2]) \n",
    "\n",
    "                if ticker_1!=ticker_2 and len(price_)>100:\n",
    "                    #Computing the times series to which we will apply the hurst exponent following the model of Ramos-Requena et.al\n",
    "                        #formula is log(price_1) - b*log(price_2) and b = std(log_ret_1)/std(log_ret_2)\n",
    "                        #Drawback, we have to have at least 100 observations\n",
    "                    coef_b = np.std(returns_[ticker_1])/np.std(returns_[ticker_2])\n",
    "                    time_series = np.log(price_[ticker_1]) - coef_b*np.log(price_[ticker_2])\n",
    "\n",
    "                    #Computing Hurst Exponent for the time series\n",
    "                    H, c, val = compute_Hc(time_series)\n",
    "\n",
    "                    #Saving the Exponent in a DataFrame with the corresponding ticker_2\n",
    "                    Hurst.append([ticker_2,H])\n",
    "\n",
    "            Hurst = pd.DataFrame(Hurst)\n",
    "            #Detemining the shortest distance between ticker_1 and ticker 2\n",
    "            Hurst = pd.DataFrame(Hurst)\n",
    "            for i in range(len(Hurst[1])): \n",
    "                if Hurst[1][i] == Hurst[1].min():\n",
    "                    row = [ticker_1,Hurst[0][i]]\n",
    "\n",
    "            #Stocking the pairs in a matrix\n",
    "            if check_double(matrix,row)==False:\n",
    "                matrix = np.vstack([matrix,row])\n",
    "\n",
    "    return matrix[1:]\n",
    "\n",
    "##############################################################################################################################\n",
    "###Executing the strategy on a rolling basis: first hundred observation which is two years to construct the pairs then execute the trading strategy in the \n",
    "#following six months, the pair selection is refreshed using the accumulated data since the first initial year \n",
    "##############################################################################################################################\n",
    "#We will use the same function used for the distance methode\n",
    "def execution_hurst_exponent_strategy(weekly_ret, adj_close_w, delta_entry, delta_exit):\n",
    "\n",
    "    #Initializing\n",
    "    #Defining the dataframe that will contain\n",
    "    hurst_exponent_portfolio=[]\n",
    "\n",
    "    #Decision window based on which the pairs will be traded\n",
    "    decision_end_date = resize_months(0,weekly_ret,24)\n",
    "    decision_window_return = clean_up(weekly_ret[0:decision_end_date])\n",
    "    decision_window_price = clean_up(adj_close_w[0:decision_end_date])\n",
    "    \n",
    "    #Trading window based on which the trading strategy will be executed\n",
    "    trading_start_date = decision_end_date + 1\n",
    "    trading_end_date = resize_months(trading_start_date,weekly_ret,6)\n",
    "    trading_window = weekly_ret[trading_start_date:trading_end_date].dropna(axis=1,thresh=10)\n",
    "\n",
    "\n",
    "    #Determining the pair trade based on a initial one year window and expanding\n",
    "    matrix = hurst_exponent_pairs(decision_window_price,decision_window_return)\n",
    "\n",
    "    #Executing the pair trade based on the distance method for all pairs in the matrix\n",
    "    portfolio_ret = pd.DataFrame(trading_distance_method(pair_return(trading_window, matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "    for row in matrix[1:]:\n",
    "        portfolio_ret = pd.concat([portfolio_ret,trading_distance_method(pair_return(trading_window,row),row,delta_entry,delta_exit)],axis=1)\n",
    "    portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1)) \n",
    "    hurst_exponent_portfolio = portfolio_ret\n",
    "\n",
    "    #Looping for the rest of the period\n",
    "    for start_date in range(1,len(weekly_ret)-132):\n",
    "\n",
    "        #Decision window based on which the pairs will be traded\n",
    "        decision_end_date = resize_months(start_date,weekly_ret,24)\n",
    "        decision_window_return = clean_up(weekly_ret[0:decision_end_date])\n",
    "        decision_window_price = clean_up(adj_close_w[0:decision_end_date])\n",
    "\n",
    "        #Trading window based on which the distance method will be evaluated and the trade strategy will be executed\n",
    "        trading_start_date = decision_end_date + 1\n",
    "        trading_end_date = resize_months(trading_start_date,weekly_ret,6)\n",
    "        if trading_end_date>len(weekly_ret):\n",
    "            trading_end_date = len(weekly_ret)\n",
    "        trading_window = weekly_ret[trading_start_date:trading_end_date].dropna(axis=1,thresh=10)\n",
    "\n",
    "        #Determining the pair trade based on a initial one year window and expanding\n",
    "        matrix = hurst_exponent_pairs(decision_window_price,decision_window_return)\n",
    "\n",
    "\n",
    "        #Executing the pair trade based on the distance method\n",
    "        portfolio_ret = pd.DataFrame(trading_distance_method(pair_return(trading_window, matrix[0]), matrix[0],delta_entry,delta_exit))\n",
    "        for row in matrix[1:]:\n",
    "            portfolio_ret = pd.concat([portfolio_ret,trading_distance_method(pair_return(trading_window,row), row,delta_entry,delta_exit)],axis=1)\n",
    "        portfolio_ret = pd.DataFrame(portfolio_ret.sum(axis=1))\n",
    "        hurst_exponent_portfolio = pd.concat([hurst_exponent_portfolio,portfolio_ret],axis=0)\n",
    "    hurst_exponent_portfolio.rename(columns={0:'Hurst Exponent Portfolio'},inplace = True)\n",
    "\n",
    "    #Computing the returns of the portfolio based on the distance method\n",
    "    hurst_exponent_portfolio_ret = ((hurst_exponent_portfolio - hurst_exponent_portfolio.shift(1))/hurst_exponent_portfolio.shift(1)).fillna(0)\n",
    "    hurst_exponent_portfolio_ret.rename(columns={'Hurst Exponent Portfolio':'Hurst Exponent Portfolio Returns'},inplace = True)\n",
    "    \n",
    "    return hurst_exponent_portfolio_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## HEDGING USING THE CAC40 #########################################################    \n",
    "\n",
    "#Function to extract the index data from yahoo finance and save the weekly closing prices\n",
    "def get_Index():\n",
    "    ticker = yf.Ticker('^FCHI')\n",
    "    start_date = \"1990-01-01\"\n",
    "    end_date = \"2021-03-31\"\n",
    "    \n",
    "    #Extracting the closing price \n",
    "    data = ticker.history(start = start_date,end=end_date)\n",
    "    data = pd.DataFrame(data[\"Close\"])\n",
    "    data.rename( columns = {'Close':'CAC40'},inplace = True)\n",
    "    data = data.resample(\"1W\").last()\n",
    "    return data\n",
    "\n",
    "######################################################################################################################\n",
    "#Function to compute the beta on a portfolio with the market\n",
    "######################################################################################################################\n",
    "def beta_of(portfolio , index_):\n",
    "    \n",
    "    #Initializing\n",
    "    moving_beta = []\n",
    "    index=[]\n",
    "\n",
    "    #Getting rid on missing values and inf values\n",
    "    data =  portfolio.join([portfolio,index_],axis=1)\n",
    "    \n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.dropna(axis=0)\n",
    "    \n",
    "    #Adjusting the run_time of the loop\n",
    "    if len(data) == 27 :\n",
    "        adjust = 0 \n",
    "    elif len(data)>27:\n",
    "        adjust = 1\n",
    "    elif len(data) < 27: \n",
    "        adjust = len(data) - 27\n",
    "        \n",
    "    for start_date in range(len(data)-26-adjust):\n",
    "        \n",
    "        #Defining the rolling window\n",
    "        end_date = resize_months(start_date,data,6)\n",
    "        if len(data)<end_date: \n",
    "            end_date = len(data)\n",
    "\n",
    "        \n",
    "        index.append(data.index[end_date-1])\n",
    "        window = data[start_date:end_date]\n",
    "               \n",
    "        #Running the regression on the rolling window\n",
    "        Y = window[data.columns[0]]\n",
    "        X = window[data.columns[1]]\n",
    "        X = sm.add_constant(X)\n",
    "        ols_regression = sm.OLS(Y,X).fit()\n",
    "        moving_beta.append(ols_regression.params[1])\n",
    "        \n",
    "    #Reindexing\n",
    "    moving_beta = pd.DataFrame(moving_beta)\n",
    "    for i in range(0,len(moving_beta)):\n",
    "        moving_beta.rename(index={i:index[i]},inplace = True)\n",
    "    moving_beta.rename(columns={0:'Beta '+data.columns[0]},inplace = True)\n",
    "    return moving_beta\n",
    "\n",
    "######################################################################################################################\n",
    "#Function to hedge the portfolio\n",
    "######################################################################################################################\n",
    "def hedged_portfolio(return_p,return_index):\n",
    "    weight = pd.DataFrame(1 - 1/beta_of(return_p,return_index))\n",
    "    df = pd.concat([return_p,return_index],axis=1).dropna(axis=0)\n",
    "    df = df.join(weight).dropna(axis=0)\n",
    "    df = pd.DataFrame(df[df.columns[0]]+df[df.columns[2]]*df[df.columns[1]])\n",
    "    df.rename(columns={0:return_p.columns[0]},inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FB2A.DE\n",
      "AAPL\n",
      "BKNG34.SA\n",
      "SU.PA\n",
      "TKWY.AS\n",
      "GOOGL\n",
      "STLA.PA\n",
      "005930.KS\n",
      "ABBN.SW\n",
      "ACN\n",
      "ADBE\n",
      "ADE.OL\n",
      "AIR.PA\n",
      "ALD.PA\n",
      "ALV\n",
      "ALO.PA\n",
      "AMS.MC\n",
      "AMZN\n",
      "ASML.AS\n",
      "ASSA-B.ST\n",
      "ATCO-A.ST\n",
      "ATE.PA\n",
      "ATO.PA\n",
      "AVGO34.SA\n",
      "AVV.L\n",
      "BMW.DE\n",
      "BRE.MI\n",
      "CAP.PA\n",
      "CCC.L\n",
      "CERV.MI\n",
      "CON.DE\n",
      "CRM\n",
      "CSCO\n",
      "CTXS\n",
      "DAI.DE\n",
      "DEC.PA\n",
      "DEMANT.CO\n",
      "DHER.DE\n",
      "DLG.DE\n",
      "DSY.PA\n",
      "DTE.DE\n",
      "DVT.PA\n",
      "EBA\n",
      "EDEN.PA\n",
      "ELIOR.PA\n",
      "ELISA.HE\n",
      "EN.PA\n",
      "SIE.DE\n",
      "EO.PA\n",
      "ERIC-B.ST\n",
      "ETL.PA\n",
      "FFP.PA\n",
      "FII.PA\n",
      "FLS.CO\n",
      "FNAC.PA\n",
      "FR.PA\n",
      "GEBN.SW\n",
      "GIB-A.TO\n",
      "GLW\n",
      "GN.CO\n",
      "HEXA-B.ST\n",
      "HLE.DE\n",
      "HO.PA\n",
      "IDR.MC\n",
      "IFX.DE\n",
      "ILD.PA\n",
      "INTC\n",
      "IP.MI\n",
      "JNPR\n",
      "JUN3.DE\n",
      "KBX.DE\n",
      "KGX.DE\n",
      "KPN.AS\n",
      "TLND\n",
      "CLNX.MC\n",
      "ELUX-B.ST\n",
      "ZAL.DE\n",
      "WRTBY\n",
      "WLN.PA\n",
      "WKL.AS\n",
      "WDAY.MX\n",
      "WAF.DE\n",
      "VOD.L\n",
      "VOW3.DE\n",
      "VOLV-B.ST\n",
      "VIV.PA\n",
      "VACN.SW\n",
      "UBER\n",
      "LDO.MI\n",
      "LOGN.SW\n",
      "LR.PA\n",
      "LYFT\n",
      "ML.PA\n",
      "MMB.PA\n",
      "MMT.PA\n",
      "MSFT\n",
      "MTX.F\n",
      "NOKIA.HE\n",
      "TXN\n",
      "TSM\n",
      "TMV.DE\n",
      "TIT.MI\n",
      "TIETO.HE\n",
      "TFI.PA\n",
      "TEP.PA\n",
      "TEMN.SW\n",
      "TEL2-B.ST\n",
      "TEL.OL\n",
      "TEF.MC\n",
      "SW.PA\n",
      "SOP.PA\n",
      "SOON.SW\n",
      "SKF-B.ST\n",
      "SIGN.SW\n",
      "SGE.L\n",
      "SCMN.SW\n",
      "SCHP.SW\n",
      "SCHB.OL\n",
      "SAP.DE\n",
      "SAND.ST\n",
      "SAF.PA\n",
      "RR.L\n",
      "RMV.L\n",
      "RIB.DE\n",
      "REL.L\n",
      "RAND\n",
      "PSON.L\n",
      "PSM.DE\n",
      "PRX.AS\n",
      "PROX.BR\n",
      "POM.PA\n",
      "PIRC.MI\n",
      "PFV.DE\n",
      "PANW\n",
      "PAGE.L\n",
      "OSR.DE\n",
      "ORCL\n",
      "ORA.PA\n",
      "O2D.VI\n",
      "NOW\n",
      "NEXI.MI\n",
      "NEX.PA\n",
      "NETC.CO\n",
      "MU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-624-731fceb5fc4c>:39: RuntimeWarning: invalid value encountered in log\n",
      "  daily_ret = np.log(adj_close) - np.log(adj_close.shift(1))\n",
      "<ipython-input-624-731fceb5fc4c>:40: RuntimeWarning: invalid value encountered in log\n",
      "  weekly_ret = np.log(adj_close_w) - np.log(adj_close_w.shift(1))\n"
     ]
    }
   ],
   "source": [
    "#Defining ticker list + end and start date\n",
    "ticker_list = ['NFLX','FB2A.DE','AAPL','BKNG34.SA','SU.PA','TKWY.AS','GOOGL',\"STLA.PA\",\n",
    "               \"005930.KS\",\"ABBN.SW\",\"ACN\",\"ADBE\",\"ADE.OL\", \"AIR.PA\",\n",
    "               \"ALD.PA\",\"ALV\",\"ALO.PA\",\"AMS.MC\",\"AMZN\",\"ASML.AS\",\"ASSA-B.ST\",\"ATCO-A.ST\",\n",
    "               \"ATE.PA\",\"ATO.PA\",\"AVGO34.SA\",\"AVV.L\",\"BMW.DE\",\"BRE.MI\",\"CAP.PA\",\"CCC.L\",\n",
    "               \"CERV.MI\",\"CON.DE\",\"CRM\",\"CSCO\",\"CTXS\",\"DAI.DE\",\"DEC.PA\",\"DEMANT.CO\",\"DHER.DE\",\n",
    "               \"DLG.DE\",\"DSY.PA\",\"DTE.DE\",\"DVT.PA\",\"EBA\",\"EDEN.PA\",\"ELIOR.PA\",\"ELISA.HE\",\n",
    "               \"EN.PA\",\"SIE.DE\",\"EO.PA\",\"ERIC-B.ST\",\"ETL.PA\",\"FFP.PA\",\"FII.PA\",\"FLS.CO\",\"FNAC.PA\",\n",
    "               \"FR.PA\",\"GEBN.SW\",\"GIB-A.TO\",\"GLW\",\"GN.CO\",\"HEXA-B.ST\",\"HLE.DE\",\"HO.PA\",\"IDR.MC\",\n",
    "               \"IFX.DE\",\"ILD.PA\",\"INTC\",\"IP.MI\",\"JNPR\",\"JUN3.DE\",\"KBX.DE\",\"KGX.DE\",\"KPN.AS\",\n",
    "               \"TLND\",\"CLNX.MC\",\"ELUX-B.ST\",\"ZAL.DE\",\"WRTBY\",\"WLN.PA\",\"WKL.AS\",\"WDAY.MX\",\n",
    "               \"WAF.DE\",\"VOD.L\",\"VOW3.DE\",\"VOLV-B.ST\",\"VIV.PA\",\"VACN.SW\",\"UBER\",\"LDO.MI\",\n",
    "               \"LOGN.SW\",\"LR.PA\",\"LYFT\",\"ML.PA\",\"MMB.PA\",\"MMT.PA\",\"MSFT\",\"MTX.F\",\"NOKIA.HE\",\n",
    "               \"TXN\",\"TSM\",\"TMV.DE\",\"TIT.MI\",\"TIETO.HE\",\"TFI.PA\",\"TEP.PA\",\"TEMN.SW\",\"TEL2-B.ST\",\n",
    "               \"TEL.OL\",\"TEF.MC\",\"SW.PA\",\"SOP.PA\",\"SOON.SW\",\"SKF-B.ST\",\"SIGN.SW\",\n",
    "               \"SGE.L\",\"SCMN.SW\",\"SCHP.SW\",\"SCHB.OL\",\"SAP.DE\",\"SAND.ST\",\"SAF.PA\",\"RR.L\",\"RMV.L\",\n",
    "               \"RIB.DE\",\"REL.L\",\"RAND\",\"PSON.L\",\"PSM.DE\",\"PRX.AS\",\"PROX.BR\",\"POM.PA\",\n",
    "               \"PIRC.MI\",\"PFV.DE\",\"PANW\",\"PAGE.L\",\"OSR.DE\",\"ORCL\",\"ORA.PA\",\"O2D.VI\",\"NOW\",\"NEXI.MI\",\n",
    "               \"NEX.PA\",\"NETC.CO\",\"MU\"]\n",
    "\n",
    "               \n",
    "start_date = \"1990-01-01\"\n",
    "end_date = \"2021-03-31\"\n",
    "\n",
    "#Extracting the closing prices from yahoofinance.com and making adjustment on them\n",
    "adj_close = pd.DataFrame(getData(ticker_list[0]))\n",
    "for tick in ticker_list[1:len(ticker_list)]:\n",
    "    adj_close= pd.concat([adj_close,getData(tick)],axis=1)\n",
    "    \n",
    "#Cleaning up the data by filling in the gaps\n",
    "for ticker in ticker_list:\n",
    "    Filling(adj_close[ticker])\n",
    "\n",
    "#Computing the weekly adjusted closing prices\n",
    "adj_close_w = adj_close.resample(\"1W\").last()\n",
    "    \n",
    "#Computing returns: \n",
    "daily_ret = np.log(adj_close) - np.log(adj_close.shift(1))\n",
    "weekly_ret = np.log(adj_close_w) - np.log(adj_close_w.shift(1))\n",
    "\n",
    "#Computing the in and out of sample dataframes\n",
    "in_sample_returns = weekly_ret[datetime.datetime(1990,1,2):datetime.datetime(2016,12,28)].dropna(axis=1,how='all')\n",
    "in_sample_prices = adj_close_w[datetime.datetime(1990,1,2):datetime.datetime(2016,12,28)].dropna(axis=1,how='all')\n",
    "out_sample_returns = weekly_ret[datetime.datetime(2016,12,29):]\n",
    "out_sample_prices = adj_close_w[datetime.datetime(2016,12,29):]\n",
    "\n",
    "#Computing the returns of the index\n",
    "return_index = pd.DataFrame((np.log(get_Index()) - np.log(get_Index()).shift(1)).dropna(axis=0))\n",
    "\n",
    "#Executing the strategies with the in_sample_data\n",
    "delta_entry = 2 \n",
    "delta_exit = 2\n",
    "portfolio_correlation = execution_correlation_strategy(in_sample_returns,delta_entry,delta_exit)\n",
    "portfolio_cointegration = execution_cointegration_method(in_sample_prices, delta_entry,delta_exit)\n",
    "portfolio_distance_model = execution_distance_model_strategy(in_sample_returns, delta_entry, delta_exit)\n",
    "portfolio_hurst_exponent = execution_hurst_exponent_strategy(in_sample_returns, adj_close_w, delta_entry, delta_exit)\n",
    "\n",
    "#Hedging the portfolios:\n",
    "portfolio_correlation = hedged_portfolio(portfolio_correlation,return_index)\n",
    "portfolio_cointegration = hedged_portfolio(portfolio_cointegration,return_index)\n",
    "portfolio_distance_model = hedged_portfolio(portfolio_distance_model,return_index)\n",
    "portfolio_hurst_exponent  = hedged_portfolio(portfolio_hurst_exponent,return_index)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
